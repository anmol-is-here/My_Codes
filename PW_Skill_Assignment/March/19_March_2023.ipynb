{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-1\n",
    "Missing values refer to the absence of data in one or more columns of a dataset. These missing values may occur due to various reasons, such as data collection errors, data corruption, or data preprocessing issues.\n",
    " \n",
    " Methods to handle missing values are-\n",
    " 1. Decision Tree\n",
    " 2. K-Nearest Neighbours\n",
    " 3. Support Vector Machines\n",
    " 4. Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-2\n",
    "#### Techniques to handle missing data are-\n",
    "1. **Deletion:** Deletion involves removing the rows or columns that contain missing values from the dataset. This technique is only recommended when the amount of missing data is small relative to the size of the dataset, and the missing data is missing completely at random (MCAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C\n",
       "0   5\n",
       "1  10\n",
       "2  11\n",
       "3   2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4],\n",
    "                   'B': [8, np.nan, np.nan, 8],\n",
    "                   'C': [5, 10, 11, 2]})\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Imputation:** Imputation involves replacing the missing values with estimated values based on the available data. There are several methods of imputation, including mean imputation, median imputation, and mode imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C\n",
       "0  1.0  8.0   5\n",
       "1  2.0  8.0  10\n",
       "2  2.0  8.0  11\n",
       "3  4.0  8.0   2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4],\n",
    "                   'B': [8, np.nan, np.nan, 8],\n",
    "                   'C': [5, 10, 11, 2]})\n",
    "\n",
    "df.fillna(df.median(), inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-3\n",
    "Imbalanced data refers to a dataset where the number of instances in one class is significantly higher or lower than the number of instances in another class. In other words, the distribution of the target variable is not uniform.\n",
    "\n",
    "* If imbalanced data is not handled, it can lead to several problems, including:\n",
    "\n",
    "=> **Biased model performance:** In the case of imbalanced data, a model may be biased towards the majority class because it has more data to learn from. This can result in poor performance on the minority class, which may be of greater importance in certain applications.\n",
    "\n",
    "=> **False positives and false negatives:** In imbalanced data, a model may predict the majority class with high accuracy, but perform poorly on the minority class. This can lead to a high number of false positives and false negatives.\n",
    "\n",
    "=> **Overfitting:** In the case of imbalanced data, a model may overfit to the majority class, resulting in poor generalization performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-4\n",
    "**Up-sampling** refers to the process of increasing the number of instances in the minority class by randomly duplicating them. This can be done using techniques such as random oversampling or SMOTE (Synthetic Minority Over-sampling Technique).\n",
    "\n",
    "  **For example**, suppose we have a dataset with 1000 instances, out of which 900 belong to class A and 100 belong to class B. Since the dataset is imbalanced, we can up-sample the minority class B by randomly duplicating its instances, resulting in a new dataset with 1800 instances, out of which 900 belong to class A and 900 belong to class B.\n",
    "\n",
    "**Down-sampling** refers to the process of decreasing the number of instances in the majority class by randomly removing them. This can be done using techniques such as random under-sampling or Tomek links.\n",
    "\n",
    "  **For example**, suppose we have a dataset with 1000 instances, out of which 900 belong to class A and 100 belong to class B. Since the dataset is imbalanced, we can down-sample the majority class A by randomly removing some of its instances, resulting in a new dataset with 200 instances, out of which 100 belong to class A and 100 belong to class B."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-5\n",
    "**Data augmentation** is a technique used to increase the size of a dataset by creating new, synthetic data from the original data. This is often done to address problems of overfitting, improve the generalization performance of machine learning models, or to balance an imbalanced dataset.\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique)** is a popular data augmentation technique. SMOTE works by creating synthetic instances of the minority class by interpolating between existing instances of that class. Specifically, for each instance in the minority class, SMOTE selects k nearest neighbors (typically k=5) and creates a new instance by linearly interpolating between the selected instance and one of its k nearest neighbors. The interpolation factor is chosen randomly between 0 and 1, and the new instance is added to the dataset.\n",
    "SMOTE is an effective technique for handling imbalanced data, as it creates new synthetic instances that are similar to existing instances in the minority class, and can thus help the machine learning model generalize better to the minority class.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-6\n",
    "**Outliers** are data points in a dataset that significantly deviate from the rest of the data points. They can be caused by errors in data collection, measurement errors, or they may represent actual extreme values in the population.\n",
    "\n",
    "It is essential to handle outliers because they can have a significant impact on the performance of machine learning models. Outliers can affect the accuracy and generalization performance of a model, as they can bias the model towards the extreme values, leading to overfitting or underfitting. Outliers can also affect the results of statistical analysis, such as the mean, variance, and standard deviation, leading to inaccurate or misleading conclusions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-7\n",
    " There are several techniques that can be used to handle missing data in customer data analysis:\n",
    "\n",
    "1. **Deletion:** One technique is to simply delete the rows or columns with missing data. This is only recommended if the missing data is a small percentage of the total dataset and if the missing data is completely at random. However, if the missing data is a large percentage of the dataset, this technique can result in a significant loss of information.\n",
    "2. **Imputation:** Another technique is to impute the missing values. This can be done using statistical methods such as mean imputation, median imputation, or mode imputation. Alternatively, more advanced techniques such as k-nearest neighbor imputation or multiple imputation can be used.\n",
    "3. **ML-based methods:** ML-based methods can also be used to handle missing data. For example, regression-based methods can be used to predict missing values based on other variables in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-8\n",
    "1. Visualization\n",
    "2. Summary statistics\n",
    "3. Imputation\n",
    "4. Statistical tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-9\n",
    "\n",
    "1. **Confusion Matrix:** A confusion matrix is a table that summarizes the performance of a classifier on a dataset. It displays the number of true positives, false positives, true negatives, and false negatives. A confusion matrix can help to evaluate the performance of the model, especially when dealing with imbalanced datasets.\n",
    "2. **Precision, Recall, and F1-score:** Precision, recall, and F1-score are metrics that are commonly used to evaluate the performance of machine learning models on imbalanced datasets. Precision is the fraction of true positive predictions among all positive predictions, while recall is the fraction of true positive predictions among all actual positive instances. F1-score is the harmonic mean of precision and recall. These metrics are useful when evaluating the performance of models on imbalanced datasets because they take into account both the false positive and false negative rates."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-10\n",
    "1. **SMOTE:** This method involves generating synthetic observations for the minority class to match the size of the majority class. SMOTE can be used in combination with random undersampling to balance the dataset. This can be done using techniques such as SMOTE Tomek from the imblearn library in Python.\n",
    "\n",
    "2. **Random undersampling:** This method involves randomly selecting a subset of observations from the majority class to match the size of the minority class. This can be done using techniques such as RandomUnderSampler from the imblearn library in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER-11\n",
    "1. **Random oversampling:** This method involves randomly duplicating observations from the minority class to match the size of the majority class. This can be done using techniques such as RandomOverSampler from the imblearn library in Python.\n",
    "2. **SMOTE:** This method involves generating synthetic observations for the minority class to match the size of the majority class. SMOTE can be used in combination with random oversampling to balance the dataset. This can be done using techniques such as SMOTE from the imblearn library in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
